# parse-urls

В репозитории два файла. В client.py находится класс,
который работает с потоками с помощью модуля threading.  

В client2.py лежит другой класс, который использует concurrent.futures.  

Оба класса решают одну задачу. В main.py есть список urls, который парсится.  

##парсинг
Для парсинга страниц используется requests.  

##примечения
Работоспособность проверена на Python 2.7 и 3.4 (для третьей ветки нужно лишь print'ы заключить в скобки) 
В client2.py есть класс Profiler, он чисто для замера скорости.  
В обоих классах есть метод get_pages, который возвращает список словарей. При успешной обработке url: {'status_code': код, 'url': url, 'content': content}, при исключении: { 'status_code': -1, 'err': объект исключения, 'url': url}.

